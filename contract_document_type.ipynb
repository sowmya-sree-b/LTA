{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_Mp3CuOSio7"
   },
   "source": [
    "# **Getting started**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FF2_yeDnCb-z"
   },
   "source": [
    "setting up the required data files location from google drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uop7UQXASW3Y",
    "outputId": "f350cbdd-c7f1-4ce2-cf44-711e5b2ec322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#lodaing files folder from google drive \n",
    "#give file path in drive.mount('file path')\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zOsznj2qSuqU"
   },
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import PlaintextCorpusReader,stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w2jZGBNGaWd7"
   },
   "source": [
    "# ***extracting data into data frame***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cgkJnLNXSwEK"
   },
   "outputs": [],
   "source": [
    "#extracting text content, name of the file, label from the file folder\n",
    "# Get the file details\n",
    "directory = []\n",
    "file = []\n",
    "title = []\n",
    "text = []\n",
    "label = []\n",
    "datapath = '/content/drive/MyDrive/workingWithP/dataCatgorize' \n",
    "for dirname, _ , filenames in os.walk(datapath):\n",
    "    #print('Directory: ', dirname)\n",
    "    #print('Subdir: ', dirname.split('/')[-1])\n",
    "    # remove the Readme.txt file\n",
    "    # will not find file in the second iteration so we skip the error\n",
    "    try:\n",
    "        filenames.remove('README.TXT')\n",
    "    except:\n",
    "        pass\n",
    "    for filename in filenames:\n",
    "        directory.append(dirname)\n",
    "        file.append(filename)\n",
    "        label.append(dirname.split('/')[-1])\n",
    "        fullpathfile = os.path.join(dirname,filename)\n",
    "        with open(fullpathfile, 'r', encoding=\"utf8\", errors='ignore') as infile:\n",
    "            intext = ''\n",
    "            firstline = True\n",
    "            for line in infile:\n",
    "                if firstline:\n",
    "                    title.append(line.replace('\\n',''))\n",
    "                    firstline = False\n",
    "                else:\n",
    "                    intext = intext + ' ' + line.replace('\\n','')\n",
    "            text.append(intext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "WQgO6o0hTNxz",
    "outputId": "4ce03c8b-9169-4a97-dc86-d2ea94cb4cb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-30d2ac4d-34f7-4a5f-9c6b-f3892a2a589a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>CONSULTING AGREEMENT  July 20, 2018  Gianluc...</td>\n",
       "      <td>Consulting Agreements</td>\n",
       "      <td>KIROMICBIOPHARMA,INC_05_11_2020-EX-10.23-CONSU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1      5. Confidentiality. 5.1 Acknowledgmen...</td>\n",
       "      <td>Consulting Agreements</td>\n",
       "      <td>MEDALISTDIVERSIFIEDREIT,INC_05_18_2020-EX-10.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>IMMUNOTOLERANCE, INC.  CONSULTING AGREEMENT ...</td>\n",
       "      <td>Consulting Agreements</td>\n",
       "      <td>PANDIONTHERAPEUTICSHOLDCOLLC_05_22_2020-EX-10....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>THIS CONSULTING AGREEMENT is made and entere...</td>\n",
       "      <td>Consulting Agreements</td>\n",
       "      <td>SPHERE3DCORP_06_24_2020-EX-10.12-CONSULTING AG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2 (c) The Consultant will faithfully, ho...</td>\n",
       "      <td>Consulting Agreements</td>\n",
       "      <td>SLINGERBAGINC_05_27_2020-EX-10.7-CONSULTING AG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30d2ac4d-34f7-4a5f-9c6b-f3892a2a589a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-30d2ac4d-34f7-4a5f-9c6b-f3892a2a589a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-30d2ac4d-34f7-4a5f-9c6b-f3892a2a589a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                  text  ...                                               file\n",
       "504    CONSULTING AGREEMENT  July 20, 2018  Gianluc...  ...  KIROMICBIOPHARMA,INC_05_11_2020-EX-10.23-CONSU...\n",
       "505    1      5. Confidentiality. 5.1 Acknowledgmen...  ...  MEDALISTDIVERSIFIEDREIT,INC_05_18_2020-EX-10.1...\n",
       "506    IMMUNOTOLERANCE, INC.  CONSULTING AGREEMENT ...  ...  PANDIONTHERAPEUTICSHOLDCOLLC_05_22_2020-EX-10....\n",
       "507    THIS CONSULTING AGREEMENT is made and entere...  ...  SPHERE3DCORP_06_24_2020-EX-10.12-CONSULTING AG...\n",
       "508        2 (c) The Consultant will faithfully, ho...  ...  SLINGERBAGINC_05_27_2020-EX-10.7-CONSULTING AG...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtering requried information from extracted data that is text content and label\n",
    "DATA_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "fulldf = pd.DataFrame(list(zip(directory, file, title, text, label)), \n",
    "               columns =['directory', 'file', 'title', 'text', 'label'])\n",
    "\n",
    "df = fulldf.filter(['text','label','file'], axis=1)\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g7u_9DXvTcxJ",
    "outputId": "c30b6b32-385b-462a-f2a8-0bf3bc5a1ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      ENTERPRISEPRODUCTSPARTNERSLP_07_08_1998-EX-10....\n",
      "1      ENERGYXXILTD_05_08_2015-EX-10.13-Transportatio...\n",
      "2      MARTINMIDSTREAMPARTNERSLP_01_23_2004-EX-10.3-T...\n",
      "3      BELLRINGBRANDS,INC_02_07_2020-EX-10.18-MASTER ...\n",
      "4      BIOFRONTERAAG_04_29_2019-EX-4.17-SUPPLY AGREEM...\n",
      "                             ...                        \n",
      "504    KIROMICBIOPHARMA,INC_05_11_2020-EX-10.23-CONSU...\n",
      "505    MEDALISTDIVERSIFIEDREIT,INC_05_18_2020-EX-10.1...\n",
      "506    PANDIONTHERAPEUTICSHOLDCOLLC_05_22_2020-EX-10....\n",
      "507    SPHERE3DCORP_06_24_2020-EX-10.12-CONSULTING AG...\n",
      "508    SLINGERBAGINC_05_27_2020-EX-10.7-CONSULTING AG...\n",
      "Name: file, Length: 509, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#preview of the file names \n",
    "print(df['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo0goSHjThtv",
    "outputId": "5f0c43ae-81f7-4c6e-9f72-b22a3e703f08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = df['file']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VpCbuXTns4_"
   },
   "source": [
    "**Text Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-c3peNZ1jKF_"
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "117RCTnxsOd-"
   },
   "outputs": [],
   "source": [
    "#general text processing \n",
    "# removing punctation and white spaces \n",
    "#setting the text to lower case\n",
    "def text_preprocess(text):\n",
    "  text=text.lower()\n",
    "  text=re.compile('[/(){}\\[\\]\\|@,;]').sub(' ', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tetwjRDwyI3W",
    "outputId": "2866059c-0d01-424c-c377-19c843f28475"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         enterprise logo appears here   enterprise...\n",
       "1                transportation agreement   table o...\n",
       "2      transportation services agreement  this mari...\n",
       "3      certain confidential information contained i...\n",
       "4          supply agreement this supply agreement  ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['text'].apply(text_preprocess)\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sodDgxFYgvmC"
   },
   "source": [
    "*punctuation removal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "TagVlHH1ajZh",
    "outputId": "ccf5df5e-5e4d-4c30-dca2-c25c966547df"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing library that has punctuation list\n",
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oUPNbzXIhbQI"
   },
   "outputs": [],
   "source": [
    "#defining a function to remove punctuation \n",
    "def remove_all_punctuation(text):\n",
    "  punctuation_remove= \"\".join([i for i in text if i not in string.punctuation])\n",
    "  return punctuation_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YdUtPTwwiFLO",
    "outputId": "673646d8-4bf2-4557-dd0e-9fcc691b92b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           enterprise logo appears here   enterprise...\n",
       "1                  transportation agreement   table o...\n",
       "2        transportation services agreement  this mari...\n",
       "3        certain confidential information contained i...\n",
       "4            supply agreement this supply agreement  ...\n",
       "                             ...                        \n",
       "504      consulting agreement  july 20  2018  gianluc...\n",
       "505      1      5 confidentiality 51 acknowledgment o...\n",
       "506      immunotolerance  inc  consulting agreement  ...\n",
       "507      this consulting agreement is made and entere...\n",
       "508          2  c  the consultant will faithfully  ho...\n",
       "Name: text, Length: 509, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling punctuation_remove function to clean the data \n",
    "df['text'] = df['text'].apply(lambda x:remove_all_punctuation(x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IMjbQ6FttFHj"
   },
   "outputs": [],
   "source": [
    "#space removel\n",
    "df['text'] = df['text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stX1w77_jLnR"
   },
   "source": [
    "*lowering the text*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "L-_ehscCiyqn"
   },
   "outputs": [],
   "source": [
    "#setting the text to lower case\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldte8zsuEoxK"
   },
   "source": [
    "*HTML removing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "18bGjGcFEoOm"
   },
   "outputs": [],
   "source": [
    "#importing package from lib\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "96lP_9KjFDPE"
   },
   "outputs": [],
   "source": [
    "#appling beautiful soup on the text \n",
    "df['text'] = [BeautifulSoup(str(text)).get_text() for text in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKhmJNRdFFB-"
   },
   "source": [
    "*unicode removal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BdB5kg7RE0yK"
   },
   "outputs": [],
   "source": [
    "#importing library \n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6wlhvyqzFKUl"
   },
   "outputs": [],
   "source": [
    "#appling unicode on the text data\n",
    "df['text'] = [unicodedata.normalize('NFKD', str(text)).encode('ascii', 'ignore').decode('utf-8', 'ignore') for text in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCQKop0eIpSq"
   },
   "source": [
    "contractions removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2I3Cl0VJWc4",
    "outputId": "487936b4-1d23-46cb-dffc-bbac7cbd6778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.0.58-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
      "\u001b[K     |████████████████████████████████| 321 kB 4.0 MB/s \n",
      "\u001b[?25hCollecting anyascii\n",
      "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
      "\u001b[K     |████████████████████████████████| 284 kB 49.0 MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85456 sha256=cfd28ef8d0e20dc5a44123f782beb2a31b117bf60c3fda6662364891a13b495c\n",
      "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.0 contractions-0.0.58 pyahocorasick-1.4.2 textsearch-0.0.21\n"
     ]
    }
   ],
   "source": [
    "#installing contraction library\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V6zzELGzIwF2"
   },
   "outputs": [],
   "source": [
    "#importing library\n",
    "import contractions\n",
    "from contractions import contractions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "D-V-zvJIIv32"
   },
   "outputs": [],
   "source": [
    "#appling the contactions list on the text data to remove all contractions\n",
    "for contraction, expansion in contractions_dict.items():\n",
    "  df['text'] = df['text'].str.replace(contraction, expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ozjlZTxjqwE"
   },
   "source": [
    "*tokenization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIgWeMMgjhhn",
    "outputId": "a7135873-8f84-49cb-92c8-517ce33460f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing library for tokenization\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "3Y2eX3nFj967"
   },
   "outputs": [],
   "source": [
    "#defining function for tokenization\n",
    "def tokenization(text):\n",
    "  tokens = word_tokenize(text)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3rSkj3VkQN7",
    "outputId": "6968224b-7629-454f-fc33-665a1dc5e110"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [enterprise, logo, appears, here, enterprise, ...\n",
       "1      [transportation, agrethement, table, of, conte...\n",
       "2      [transportation, services, agrethement, this, ...\n",
       "3      [certain, confidential, information, contained...\n",
       "4      [supply, agrethement, this, supply, agrethemen...\n",
       "                             ...                        \n",
       "504    [consulting, agrethement, july, gianluca, roti...\n",
       "505    [confidentiality, acknowledgment, of, propriet...\n",
       "506    [immunotolerance, inc, consulting, agrethement...\n",
       "507    [this, consulting, agrethement, is, made, and,...\n",
       "508    [c, the, consultant, will, faithfully, honestl...\n",
       "Name: text, Length: 509, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calling tokenization function to tokenize each word in the text content\n",
    "df['text'] = df['text'].apply(str)\n",
    "df['text'] = df['text'].apply(lambda x: tokenization(x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TF9179eBkiVG",
    "outputId": "4e7fb5bc-59a9-4f66-96c9-5cc47cf2b8d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enterprise',\n",
       " 'logo',\n",
       " 'appears',\n",
       " 'here',\n",
       " 'enterprise',\n",
       " 'transportation',\n",
       " 'company',\n",
       " 'a',\n",
       " 'division',\n",
       " 'of',\n",
       " 'enterprise',\n",
       " 'products',\n",
       " 'company',\n",
       " 'po',\n",
       " 'box',\n",
       " 'phone',\n",
       " 'contract',\n",
       " 'no',\n",
       " 'houston',\n",
       " 'tx',\n",
       " 'date',\n",
       " 'june',\n",
       " 'transportation',\n",
       " 'contract',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'is',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'by',\n",
       " 'and',\n",
       " 'between',\n",
       " 'enterprise',\n",
       " 'transportation',\n",
       " 'company',\n",
       " 'a',\n",
       " 'division',\n",
       " 'of',\n",
       " 'enterprise',\n",
       " 'products',\n",
       " 'company',\n",
       " 'carrier',\n",
       " 'and',\n",
       " 'enterprise',\n",
       " 'products',\n",
       " 'operating',\n",
       " 'lp',\n",
       " 'a',\n",
       " 'delaware',\n",
       " 'limited',\n",
       " 'partnership',\n",
       " 'po',\n",
       " 'box',\n",
       " 'houston',\n",
       " 'tx',\n",
       " 'shipper',\n",
       " 'address',\n",
       " 'city',\n",
       " 'state',\n",
       " 'shipper',\n",
       " 'is',\n",
       " 'engaged',\n",
       " 'in',\n",
       " 'business',\n",
       " 'as',\n",
       " 'a',\n",
       " 'manufacturer',\n",
       " 'distributor',\n",
       " 'or',\n",
       " 'dealer',\n",
       " 'of',\n",
       " 'chthemicals',\n",
       " 'or',\n",
       " 'petroleum',\n",
       " 'products',\n",
       " 'commodities',\n",
       " 'and',\n",
       " 'shipper',\n",
       " 'requires',\n",
       " 'transportation',\n",
       " 'of',\n",
       " 'commodities',\n",
       " 'in',\n",
       " 'intrastate',\n",
       " 'interstate',\n",
       " 'or',\n",
       " 'foreign',\n",
       " 'commerce',\n",
       " 'carrier',\n",
       " 'is',\n",
       " 'authorized',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'transportation',\n",
       " 'for',\n",
       " 'shipper',\n",
       " 'as',\n",
       " 'a',\n",
       " 'motor',\n",
       " 'contract',\n",
       " 'carrier',\n",
       " 'under',\n",
       " 'authority',\n",
       " 'issued',\n",
       " 'by',\n",
       " 'the',\n",
       " 'us',\n",
       " 'department',\n",
       " 'of',\n",
       " 'transporation',\n",
       " 'in',\n",
       " 'docket',\n",
       " 'no',\n",
       " 'mc',\n",
       " 'now',\n",
       " 'therefore',\n",
       " 'in',\n",
       " 'consideration',\n",
       " 'of',\n",
       " 'the',\n",
       " 'mutual',\n",
       " 'promises',\n",
       " 'herein',\n",
       " 'contained',\n",
       " 'the',\n",
       " 'parties',\n",
       " 'agree',\n",
       " 'as',\n",
       " 'follows',\n",
       " 'shipper',\n",
       " 'shall',\n",
       " 'tender',\n",
       " 'commodities',\n",
       " 'to',\n",
       " 'carrier',\n",
       " 'for',\n",
       " 'transportation',\n",
       " 'by',\n",
       " 'carrier',\n",
       " 'in',\n",
       " 'a',\n",
       " 'specialized',\n",
       " 'service',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'the',\n",
       " 'distinct',\n",
       " 'needs',\n",
       " 'of',\n",
       " 'shipper',\n",
       " 'in',\n",
       " 'interstate',\n",
       " 'or',\n",
       " 'foreign',\n",
       " 'commerce',\n",
       " 'between',\n",
       " 'points',\n",
       " 'in',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'shipper',\n",
       " 'shall',\n",
       " 'tender',\n",
       " 'to',\n",
       " 'carrier',\n",
       " 'and',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'transport',\n",
       " 'in',\n",
       " 'a',\n",
       " 'series',\n",
       " 'of',\n",
       " 'shipments',\n",
       " 'not',\n",
       " 'less',\n",
       " 'than',\n",
       " 'pounds',\n",
       " 'of',\n",
       " 'commodities',\n",
       " 'per',\n",
       " 'year',\n",
       " 'as',\n",
       " 'compensation',\n",
       " 'for',\n",
       " 'the',\n",
       " 'services',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'carrier',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'shipper',\n",
       " 'shall',\n",
       " 'pay',\n",
       " 'carrier',\n",
       " 'in',\n",
       " 'accordance',\n",
       " 'with',\n",
       " 'rate',\n",
       " 'appendices',\n",
       " 'making',\n",
       " 'reference',\n",
       " 'to',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'which',\n",
       " 'shall',\n",
       " 'from',\n",
       " 'time',\n",
       " 'to',\n",
       " 'time',\n",
       " 'be',\n",
       " 'agreed',\n",
       " 'to',\n",
       " 'between',\n",
       " 'the',\n",
       " 'parties',\n",
       " 'and',\n",
       " 'carriers',\n",
       " 'contract',\n",
       " 'carriage',\n",
       " 'rules',\n",
       " 'and',\n",
       " 'regulations',\n",
       " 'attached',\n",
       " 'as',\n",
       " 'exhibit',\n",
       " 'a',\n",
       " 'which',\n",
       " 'are',\n",
       " 'incorporated',\n",
       " 'in',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'by',\n",
       " 'this',\n",
       " 'reference',\n",
       " 'for',\n",
       " 'all',\n",
       " 'purposes',\n",
       " 'collectively',\n",
       " 'the',\n",
       " 'schedule',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'for',\n",
       " 'a',\n",
       " 'term',\n",
       " 'of',\n",
       " 'one',\n",
       " 'year',\n",
       " 'commencing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'date',\n",
       " 'first',\n",
       " 'above',\n",
       " 'written',\n",
       " 'thereafter',\n",
       " 'it',\n",
       " 'shall',\n",
       " 'automatically',\n",
       " 'continue',\n",
       " 'until',\n",
       " 'terminated',\n",
       " 'by',\n",
       " 'either',\n",
       " 'party',\n",
       " 'upon',\n",
       " 'not',\n",
       " 'less',\n",
       " 'than',\n",
       " 'thirty',\n",
       " 'days',\n",
       " 'prior',\n",
       " 'written',\n",
       " 'notice',\n",
       " 'to',\n",
       " 'the',\n",
       " 'other',\n",
       " 'party',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'is',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'and',\n",
       " 'conditions',\n",
       " 'on',\n",
       " 'the',\n",
       " 'reverse',\n",
       " 'side',\n",
       " 'enterprise',\n",
       " 'products',\n",
       " 'operating',\n",
       " 'lp',\n",
       " 'enterprise',\n",
       " 'transportation',\n",
       " 'company',\n",
       " 'by',\n",
       " 'enterprise',\n",
       " 'products',\n",
       " 'gp',\n",
       " 'llc',\n",
       " 'its',\n",
       " 'general',\n",
       " 'partner',\n",
       " 'shipper',\n",
       " 'by',\n",
       " 's',\n",
       " 'aw',\n",
       " 'bell',\n",
       " 'by',\n",
       " 's',\n",
       " 'gary',\n",
       " 'miller',\n",
       " 'title',\n",
       " 'executive',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'title',\n",
       " 'executive',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'terms',\n",
       " 'and',\n",
       " 'conditions',\n",
       " 'for',\n",
       " 'each',\n",
       " 'shipment',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'shipper',\n",
       " 'shall',\n",
       " 'designate',\n",
       " 'the',\n",
       " 'points',\n",
       " 'of',\n",
       " 'origin',\n",
       " 'and',\n",
       " 'destination',\n",
       " 'and',\n",
       " 'any',\n",
       " 'point',\n",
       " 'or',\n",
       " 'points',\n",
       " 'where',\n",
       " 'stopoffs',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'made',\n",
       " 'for',\n",
       " 'partial',\n",
       " 'loading',\n",
       " 'or',\n",
       " 'unloading',\n",
       " 'shipper',\n",
       " 'shall',\n",
       " 'exert',\n",
       " 'its',\n",
       " 'best',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'load',\n",
       " 'each',\n",
       " 'shipment',\n",
       " 'to',\n",
       " 'the',\n",
       " 'lawful',\n",
       " 'capacity',\n",
       " 'of',\n",
       " 'carriers',\n",
       " 'vehicle',\n",
       " 'each',\n",
       " 'shipment',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'evidenced',\n",
       " 'by',\n",
       " 'a',\n",
       " 'shipping',\n",
       " 'document',\n",
       " 'signed',\n",
       " 'by',\n",
       " 'carrier',\n",
       " 'consignor',\n",
       " 'and',\n",
       " 'consignee',\n",
       " 'showing',\n",
       " 'the',\n",
       " 'kind',\n",
       " 'and',\n",
       " 'quantity',\n",
       " 'of',\n",
       " 'commodities',\n",
       " 'received',\n",
       " 'and',\n",
       " 'delivered',\n",
       " 'by',\n",
       " 'carrier',\n",
       " 'at',\n",
       " 'the',\n",
       " 'loading',\n",
       " 'and',\n",
       " 'unloading',\n",
       " 'points',\n",
       " 'respectively',\n",
       " 'provided',\n",
       " 'however',\n",
       " 'the',\n",
       " 'provisions',\n",
       " 'of',\n",
       " 'any',\n",
       " 'shipping',\n",
       " 'document',\n",
       " 'bill',\n",
       " 'of',\n",
       " 'lading',\n",
       " 'or',\n",
       " 'other',\n",
       " 'instrument',\n",
       " 'to',\n",
       " 'the',\n",
       " 'contrary',\n",
       " 'notwithstanding',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'and',\n",
       " 'the',\n",
       " 'schedule',\n",
       " 'shall',\n",
       " 'exclusively',\n",
       " 'govern',\n",
       " 'the',\n",
       " 'relationship',\n",
       " 'of',\n",
       " 'the',\n",
       " 'parties',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'the',\n",
       " 'subject',\n",
       " 'matter',\n",
       " 'of',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'a',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'invoice',\n",
       " 'shipper',\n",
       " 'for',\n",
       " 'the',\n",
       " 'services',\n",
       " 'provided',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'promptly',\n",
       " 'upon',\n",
       " 'performance',\n",
       " 'all',\n",
       " 'sums',\n",
       " 'due',\n",
       " 'under',\n",
       " 'any',\n",
       " 'invoice',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'payable',\n",
       " 'without',\n",
       " 'discount',\n",
       " 'upon',\n",
       " 'receipt',\n",
       " 'of',\n",
       " 'the',\n",
       " 'invoice',\n",
       " 'amounts',\n",
       " 'more',\n",
       " 'than',\n",
       " 'days',\n",
       " 'past',\n",
       " 'due',\n",
       " 'shall',\n",
       " 'bear',\n",
       " 'interest',\n",
       " 'from',\n",
       " 'the',\n",
       " 'due',\n",
       " 'date',\n",
       " 'to',\n",
       " 'the',\n",
       " 'date',\n",
       " 'of',\n",
       " 'payment',\n",
       " 'at',\n",
       " 'the',\n",
       " 'lesser',\n",
       " 'of',\n",
       " 'the',\n",
       " 'rate',\n",
       " 'of',\n",
       " 'interest',\n",
       " 'established',\n",
       " 'by',\n",
       " 'chase',\n",
       " 'manhattan',\n",
       " 'bank',\n",
       " 'new',\n",
       " 'york',\n",
       " 'ny',\n",
       " 'from',\n",
       " 'time',\n",
       " 'to',\n",
       " 'time',\n",
       " 'as',\n",
       " 'its',\n",
       " 'prime',\n",
       " 'rate',\n",
       " 'plus',\n",
       " 'two',\n",
       " 'percent',\n",
       " 'or',\n",
       " 'the',\n",
       " 'maximum',\n",
       " 'nonusurious',\n",
       " 'interest',\n",
       " 'rate',\n",
       " 'which',\n",
       " 'may',\n",
       " 'be',\n",
       " 'charged',\n",
       " 'shipper',\n",
       " 'pursuant',\n",
       " 'to',\n",
       " 'applicable',\n",
       " 'texas',\n",
       " 'law',\n",
       " 'article',\n",
       " 'texas',\n",
       " 'rev',\n",
       " 'civ',\n",
       " 'stat',\n",
       " 'as',\n",
       " 'amended',\n",
       " 'b',\n",
       " 'all',\n",
       " 'sums',\n",
       " 'due',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'are',\n",
       " 'payable',\n",
       " 'at',\n",
       " 'carriers',\n",
       " 'offices',\n",
       " 'in',\n",
       " 'houston',\n",
       " 'harris',\n",
       " 'county',\n",
       " 'texas',\n",
       " 'a',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'perform',\n",
       " 'services',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'as',\n",
       " 'an',\n",
       " 'independent',\n",
       " 'contractor',\n",
       " 'and',\n",
       " 'shall',\n",
       " 'have',\n",
       " 'exclusive',\n",
       " 'control',\n",
       " 'and',\n",
       " 'direction',\n",
       " 'of',\n",
       " 'its',\n",
       " 'themployees',\n",
       " 'and',\n",
       " 'exclusive',\n",
       " 'responsibility',\n",
       " 'to',\n",
       " 'shipper',\n",
       " 'for',\n",
       " 'any',\n",
       " 'of',\n",
       " 'carriers',\n",
       " 'owneroperator',\n",
       " 'contractors',\n",
       " 'engaged',\n",
       " 'in',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'pay',\n",
       " 'all',\n",
       " 'wages',\n",
       " 'local',\n",
       " 'state',\n",
       " 'and',\n",
       " 'federal',\n",
       " 'payroll',\n",
       " 'taxes',\n",
       " 'or',\n",
       " 'contributions',\n",
       " 'or',\n",
       " 'taxes',\n",
       " 'for',\n",
       " 'unthemployment',\n",
       " 'insurance',\n",
       " 'workers',\n",
       " 'compensation',\n",
       " 'pensions',\n",
       " 'social',\n",
       " 'security',\n",
       " 'and',\n",
       " 'related',\n",
       " 'protection',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'its',\n",
       " 'themployees',\n",
       " 'b',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'at',\n",
       " 'its',\n",
       " 'sole',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'expense',\n",
       " 'furnish',\n",
       " 'all',\n",
       " 'vehicles',\n",
       " 'fuel',\n",
       " 'oil',\n",
       " 'tires',\n",
       " 'and',\n",
       " 'other',\n",
       " 'parts',\n",
       " 'maintenance',\n",
       " 'supplies',\n",
       " 'drivers',\n",
       " 'and',\n",
       " 'equipment',\n",
       " 'necessary',\n",
       " 'or',\n",
       " 'required',\n",
       " 'for',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'the',\n",
       " 'services',\n",
       " 'to',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'procure',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'all',\n",
       " 'licenses',\n",
       " 'and',\n",
       " 'permits',\n",
       " 'required',\n",
       " 'by',\n",
       " 'local',\n",
       " 'state',\n",
       " 'or',\n",
       " 'federal',\n",
       " 'law',\n",
       " 'and',\n",
       " 'comply',\n",
       " 'with',\n",
       " 'all',\n",
       " 'applicable',\n",
       " 'laws',\n",
       " 'regulations',\n",
       " 'and',\n",
       " 'governmental',\n",
       " 'orders',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'the',\n",
       " 'services',\n",
       " 'to',\n",
       " 'be',\n",
       " 'provided',\n",
       " 'under',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'a',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'at',\n",
       " 'its',\n",
       " 'sole',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'expense',\n",
       " 'procure',\n",
       " 'and',\n",
       " 'maintain',\n",
       " 'liability',\n",
       " 'insurance',\n",
       " 'with',\n",
       " 'a',\n",
       " 'reputable',\n",
       " 'and',\n",
       " 'financially',\n",
       " 'responsible',\n",
       " 'insurance',\n",
       " 'carrier',\n",
       " 'or',\n",
       " 'carriers',\n",
       " 'properly',\n",
       " 'insuring',\n",
       " 'carrier',\n",
       " 'against',\n",
       " 'liability',\n",
       " 'and',\n",
       " 'claims',\n",
       " 'for',\n",
       " 'injuries',\n",
       " 'to',\n",
       " 'persons',\n",
       " 'including',\n",
       " 'injuries',\n",
       " 'resulting',\n",
       " 'in',\n",
       " 'death',\n",
       " 'and',\n",
       " 'for',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'property',\n",
       " 'in',\n",
       " 'amounts',\n",
       " 'not',\n",
       " 'less',\n",
       " 'than',\n",
       " 'the',\n",
       " 'minimum',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'financial',\n",
       " 'responsibility',\n",
       " 'for',\n",
       " 'motor',\n",
       " 'carriers',\n",
       " 'prescribed',\n",
       " 'by',\n",
       " 'the',\n",
       " 'u',\n",
       " 's',\n",
       " 'department',\n",
       " 'of',\n",
       " 'transportation',\n",
       " 'cfr',\n",
       " 's',\n",
       " 'et',\n",
       " 'seq',\n",
       " 'b',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'the',\n",
       " 'limits',\n",
       " 'of',\n",
       " 'the',\n",
       " 'insurance',\n",
       " 'coverages',\n",
       " 'specified',\n",
       " 'in',\n",
       " 'paragraph',\n",
       " 'a',\n",
       " 'above',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'defend',\n",
       " 'indthemnify',\n",
       " 'and',\n",
       " 'hold',\n",
       " 'shipper',\n",
       " 'harmless',\n",
       " 'from',\n",
       " 'and',\n",
       " 'against',\n",
       " 'all',\n",
       " 'loss',\n",
       " 'damage',\n",
       " 'expense',\n",
       " 'actions',\n",
       " 'and',\n",
       " 'claims',\n",
       " 'for',\n",
       " 'injury',\n",
       " 'to',\n",
       " 'persons',\n",
       " 'including',\n",
       " 'injury',\n",
       " 'resulting',\n",
       " 'in',\n",
       " 'death',\n",
       " 'and',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'or',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'property',\n",
       " 'arising',\n",
       " 'out',\n",
       " 'of',\n",
       " 'or',\n",
       " 'in',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'carriers',\n",
       " 'negligence',\n",
       " 'in',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'provided',\n",
       " 'however',\n",
       " 'carrier',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'be',\n",
       " 'liable',\n",
       " 'for',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'or',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'commodities',\n",
       " 'transported',\n",
       " 'to',\n",
       " 'the',\n",
       " 'extent',\n",
       " 'such',\n",
       " 'loss',\n",
       " 'or',\n",
       " 'damage',\n",
       " 'was',\n",
       " 'not',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'carriers',\n",
       " 'negligence',\n",
       " 'and',\n",
       " 'was',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'an',\n",
       " 'act',\n",
       " 'of',\n",
       " 'god',\n",
       " 'the',\n",
       " 'public',\n",
       " 'enthemy',\n",
       " 'the',\n",
       " 'act',\n",
       " 'of',\n",
       " 'shipper',\n",
       " 'or',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'vice',\n",
       " 'of',\n",
       " 'the',\n",
       " 'commodities',\n",
       " 'where',\n",
       " 'personal',\n",
       " 'injury',\n",
       " 'or',\n",
       " 'death',\n",
       " 'or',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'or',\n",
       " 'damage',\n",
       " 'to',\n",
       " 'property',\n",
       " 'arises',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'joint',\n",
       " 'negligence',\n",
       " 'of',\n",
       " 'carrier',\n",
       " 'and',\n",
       " 'shipper',\n",
       " 'carriers',\n",
       " 'duty',\n",
       " 'of',\n",
       " 'indthemnification',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'in',\n",
       " 'proportion',\n",
       " 'to',\n",
       " 'its',\n",
       " 'allocable',\n",
       " 'share',\n",
       " 'of',\n",
       " 'such',\n",
       " 'joint',\n",
       " 'negligence',\n",
       " 'in',\n",
       " 'no',\n",
       " 'event',\n",
       " 'shall',\n",
       " 'carrier',\n",
       " 'be',\n",
       " 'liable',\n",
       " 'for',\n",
       " 'any',\n",
       " 'lost',\n",
       " 'profits',\n",
       " 'or',\n",
       " 'special',\n",
       " 'indirect',\n",
       " 'or',\n",
       " 'consequential',\n",
       " 'damages',\n",
       " 'if',\n",
       " 'either',\n",
       " 'party',\n",
       " 'is',\n",
       " 'rendered',\n",
       " 'unable',\n",
       " 'wholly',\n",
       " 'or',\n",
       " 'in',\n",
       " 'part',\n",
       " 'by',\n",
       " 'force',\n",
       " 'majeure',\n",
       " 'or',\n",
       " 'any',\n",
       " 'other',\n",
       " 'cause',\n",
       " 'of',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'not',\n",
       " 'reasonably',\n",
       " 'foreseeable',\n",
       " 'or',\n",
       " 'within',\n",
       " 'its',\n",
       " 'control',\n",
       " 'to',\n",
       " 'perform',\n",
       " 'or',\n",
       " 'comply',\n",
       " 'with',\n",
       " 'any',\n",
       " 'obligation',\n",
       " 'or',\n",
       " 'condition',\n",
       " 'of',\n",
       " 'this',\n",
       " 'contract',\n",
       " 'then',\n",
       " 'upon',\n",
       " 'giving',\n",
       " 'notice',\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of tokens from one file\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcPduTDblFHK"
   },
   "source": [
    "*stop word removal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AedO4GX5kq7I",
    "outputId": "5281ff3f-dd16-49d6-ea0a-9e61814a6d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk lib has already imported \n",
    "#stop words in given library\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "OaxCbPrelptL"
   },
   "outputs": [],
   "source": [
    "#defining function for stop words\n",
    "def remove_stopwords(text):\n",
    "  output = [i for i in text if i not in stopwords]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IW8--YhWV7N0",
    "outputId": "eabe569d-8276-4b95-dc08-5e6a4ad605d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [enterprise, logo, appears, enterprise, transp...\n",
       "1      [transportation, agrethement, table, contents,...\n",
       "2      [transportation, services, agrethement, marchn...\n",
       "3      [certain, confidential, information, contained...\n",
       "4      [supply, agrethement, supply, agrethement, agr...\n",
       "                             ...                        \n",
       "504    [consulting, agrethement, july, gianluca, roti...\n",
       "505    [confidentiality, acknowledgment, proprietary,...\n",
       "506    [immunotolerance, inc, consulting, agrethement...\n",
       "507    [consulting, agrethement, made, entered, june,...\n",
       "508    [c, consultant, faithfully, honestly, diligent...\n",
       "Name: text, Length: 509, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#appling the stopwords function to the text content\n",
    "df['text'] = df['text'].apply(lambda x:remove_stopwords(x))\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW-yrXhpmt8T"
   },
   "source": [
    "*lemmatization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oqwVjaLmgzX",
    "outputId": "2279b336-9414-4c86-f6ba-88e435f1fa70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing lemmatization from lib\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ey9UZyjmns1w"
   },
   "outputs": [],
   "source": [
    "#defining functioon as object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "uTD1WdMTn52s"
   },
   "outputs": [],
   "source": [
    "#defining the lemmatization function\n",
    "def lemmatizer(text):\n",
    "  lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "  return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Zm88H-ncofop"
   },
   "outputs": [],
   "source": [
    "#appling lemmization function to text content\n",
    "df['text'] = df['text'].apply(lambda x: lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUvvc5rMKZCN"
   },
   "source": [
    "*null values removing*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tGn69ekQpGLy"
   },
   "outputs": [],
   "source": [
    "# removing white spaces or null values from the text content \n",
    "df = df[~(df.text.str.strip() == '')]\n",
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klmvNbIqcrgS"
   },
   "source": [
    "# **splitting data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-iNnzFRffOa"
   },
   "source": [
    "splitting corpus into two parts for testing and training the model.\n",
    "training - 80% \n",
    "test - 20 % \n",
    "so the corpus has to spilt in the ratio of 80:20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "V1TNmcWYWzuH"
   },
   "outputs": [],
   "source": [
    "# importing spillitng function from sklearn library\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1okE2k8GWz5Q",
    "outputId": "0f59f643-401f-446d-cfc0-0ff323cd5081"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((407,), (102,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividing up labels and data for testing as well as training\n",
    "train_corpus_set, test_corpus_set, train_label_names_set, test_label_names_set = train_test_split(np.array(df['text'].apply(lambda x:np.str_(x))),\n",
    "np.array(df['label']), \n",
    "test_size=0.20, \n",
    "random_state=42)\n",
    "\n",
    "train_corpus_set.shape, test_corpus_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J9NMTMQAhV0"
   },
   "source": [
    "# **TF-IDF and classification models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWEplJ7XZalN"
   },
   "source": [
    "## **features extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bl6uWaxEacey"
   },
   "source": [
    "## *TF-IDF* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VdqUwwD4ZZgA"
   },
   "outputs": [],
   "source": [
    "#importing tfidf package from skleran\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "UiLwZNI8K8lO"
   },
   "outputs": [],
   "source": [
    "#normilization of TF-IDF algorithm\n",
    "tfidf_tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "89tIzV9vW9Y9"
   },
   "outputs": [],
   "source": [
    "#appling the TF-IDF algorithm to extract features \n",
    "tfidf_tv_train_features = tfidf_tv.fit_transform(train_corpus_set)\n",
    "tfidf_tv_test_features = tfidf_tv.transform(test_corpus_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAKtZYoO7KwY",
    "outputId": "08f85b72-09a6-432c-dabe-7e3e12822ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF model:\n",
      " Train features: (407, 23599) \n",
      " Test features: (102, 23599)\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF model:\\n','Train features:', tfidf_tv_train_features.shape,'\\n', 'Test features:', tfidf_tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B05Gb4fNjkKP"
   },
   "source": [
    "## **classification model and evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-2prQ3IMYcs"
   },
   "source": [
    "## *SVM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "tUhkSwwuXCdx"
   },
   "outputs": [],
   "source": [
    "# importing SVM algorithm from sklearn library\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDJNNqc57cBk",
    "outputId": "68e0eb93-09b1-4938-96f7-067b49487309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, random_state=42)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying the SVM algorithm on training data to train the model\n",
    "svm_model = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm_model.fit(tfidf_tv_train_features, train_label_names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDadPkkLNFB5",
    "outputId": "0ea8f31a-d19c-474f-85db-182e42189f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      Agency Agreements       0.50      0.50      0.50         2\n",
      "            Co_Branding       0.67      0.50      0.57         4\n",
      "          Collaboration       0.75      0.86      0.80         7\n",
      "  Consulting Agreements       0.75      1.00      0.86         3\n",
      "            Development       0.67      0.80      0.73         5\n",
      "            Distributor       0.90      0.82      0.86        11\n",
      "            Endorsement       0.00      0.00      0.00         1\n",
      "  Endorsement Agreement       0.00      0.00      0.00         1\n",
      "              Franchise       1.00      1.00      1.00         3\n",
      "                Hosting       0.60      0.60      0.60         5\n",
      "                     IP       1.00      1.00      1.00         1\n",
      "          Joint Venture       0.00      0.00      0.00         1\n",
      " Joint Venture _ Filing       0.40      0.67      0.50         3\n",
      "     License_Agreements       0.33      0.60      0.43         5\n",
      "            Maintenance       0.55      1.00      0.71         6\n",
      "          Manufacturing       0.25      1.00      0.40         1\n",
      "              Marketing       0.00      0.00      0.00         3\n",
      "Non_Compete_Non_Solicit       0.00      0.00      0.00         1\n",
      "            Outsourcing       0.00      0.00      0.00         9\n",
      "              Promotion       0.00      0.00      0.00         2\n",
      "               Reseller       0.00      0.00      0.00         1\n",
      "                Service       0.67      0.75      0.71         8\n",
      "            Sponsorship       0.67      0.80      0.73         5\n",
      "     Strategic Alliance       0.67      0.57      0.62         7\n",
      "                 Supply       0.50      0.67      0.57         3\n",
      "         Transportation       1.00      0.50      0.67         4\n",
      "\n",
      "               accuracy                           0.61       102\n",
      "              macro avg       0.46      0.52      0.47       102\n",
      "           weighted avg       0.56      0.61      0.57       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification report of SVM Model\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = svm_model.predict(tfidf_tv_test_features)\n",
    "print(classification_report(test_label_names_set, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiW4x1eUA810"
   },
   "source": [
    "## *logestic regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E2Wd_zRHE-Ag"
   },
   "outputs": [],
   "source": [
    "#impoorting logistic regression algorithm from sklearn library\n",
    "import sklearn.linear_model as sk\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NofzNDIaBGT7",
    "outputId": "18d5d6a1-aad6-4ed1-e60c-9efdcb3bca83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying the SVM algorithm on training data to train the model\n",
    "lr_model = LogisticRegression(penalty='l2', solver='lbfgs', multi_class='ovr',\n",
    "                        max_iter=1000, C=1, random_state=42)\n",
    "lr_model.fit(tfidf_tv_train_features, train_label_names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UwT9SG4lJnIO",
    "outputId": "6d477df6-9287-494f-8140-ad0a2faf8058"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      Agency Agreements       0.00      0.00      0.00         2\n",
      "            Co_Branding       1.00      0.50      0.67         4\n",
      "          Collaboration       1.00      0.43      0.60         7\n",
      "  Consulting Agreements       1.00      1.00      1.00         3\n",
      "            Development       0.36      0.80      0.50         5\n",
      "            Distributor       0.90      0.82      0.86        11\n",
      "            Endorsement       0.00      0.00      0.00         1\n",
      "  Endorsement Agreement       0.00      0.00      0.00         1\n",
      "              Franchise       1.00      1.00      1.00         3\n",
      "                Hosting       0.50      0.20      0.29         5\n",
      "                     IP       1.00      1.00      1.00         1\n",
      "          Joint Venture       0.00      0.00      0.00         1\n",
      " Joint Venture _ Filing       0.00      0.00      0.00         3\n",
      "     License_Agreements       0.31      0.80      0.44         5\n",
      "            Maintenance       0.21      1.00      0.35         6\n",
      "          Manufacturing       0.00      0.00      0.00         1\n",
      "              Marketing       0.00      0.00      0.00         3\n",
      "Non_Compete_Non_Solicit       0.00      0.00      0.00         1\n",
      "            Outsourcing       0.00      0.00      0.00         9\n",
      "              Promotion       0.00      0.00      0.00         2\n",
      "               Reseller       0.00      0.00      0.00         1\n",
      "                Service       0.71      0.62      0.67         8\n",
      "            Sponsorship       0.56      1.00      0.71         5\n",
      "     Strategic Alliance       0.40      0.29      0.33         7\n",
      "                 Supply       0.50      0.33      0.40         3\n",
      "         Transportation       1.00      0.25      0.40         4\n",
      "\n",
      "               accuracy                           0.49       102\n",
      "              macro avg       0.40      0.39      0.35       102\n",
      "           weighted avg       0.51      0.49      0.45       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#testing and classification report of LOgestic regression \n",
    "y_pred = lr_model.predict(tfidf_tv_test_features)\n",
    "print(classification_report(test_label_names_set, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYJI240fLxjf"
   },
   "source": [
    "# **word2vec and other models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haROD-s1O_H8"
   },
   "source": [
    "# **features extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hIn-WrLVM2UJ"
   },
   "source": [
    "## word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "cA5-w2THNHNW"
   },
   "outputs": [],
   "source": [
    "#importing gensim library to get Word2Vec algorithm\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "e6uW9YieJpeu"
   },
   "outputs": [],
   "source": [
    "#tokenization for the model\n",
    "tokenized_train = [nltk.tokenize.word_tokenize(text)\n",
    "                   for text in train_corpus_set]\n",
    "tokenized_test = [nltk.tokenize.word_tokenize(text)\n",
    "                   for text in test_corpus_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "62loCBR9NLOp"
   },
   "outputs": [],
   "source": [
    "#setting up the word2vec alogithm \n",
    "w2v_features_num = 300\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, \n",
    "            size=w2v_features_num, \n",
    "            window=10,\n",
    "            min_count=2, \n",
    "            sg = 0, \n",
    "            iter=5, workers=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "ljoEVIg_NYNA"
   },
   "outputs": [],
   "source": [
    "#features extraction using word2vec\n",
    "#fitting the tokenized training data to the algorithm \n",
    "def document_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)\n",
    "    \n",
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = document_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
    "                                                     num_features=w2v_features_num)\n",
    "avg_wv_test_features = document_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
    "                                                    num_features=w2v_features_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g8VeWkxPQZC"
   },
   "source": [
    "## **prediction model and  evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApUk__fSNnMZ"
   },
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tOhMg4G5NmKS",
    "outputId": "03f53dbd-6274-44a4-d761-783937b3dc35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the dataframe to the logistic regression algorithm \n",
    "#training the model with the training data\n",
    "lr_model = LogisticRegression(penalty='l2', solver='lbfgs', multi_class='ovr',\n",
    "                        max_iter=1000, C=1, random_state=42)\n",
    "lr_model.fit(avg_wv_train_features, train_label_names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4UwIi5BOLEQ",
    "outputId": "6544cd0b-f9d0-47a5-eadb-e4a0cc67fa90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "      Agency Agreements       0.00      0.00      0.00         2\n",
      "            Co_Branding       1.00      0.50      0.67         4\n",
      "          Collaboration       0.50      0.14      0.22         7\n",
      "  Consulting Agreements       0.00      0.00      0.00         3\n",
      "            Development       0.17      0.20      0.18         5\n",
      "            Distributor       0.78      0.64      0.70        11\n",
      "            Endorsement       0.00      0.00      0.00         1\n",
      "  Endorsement Agreement       0.00      0.00      0.00         1\n",
      "              Franchise       1.00      1.00      1.00         3\n",
      "                Hosting       0.50      0.20      0.29         5\n",
      "                     IP       1.00      1.00      1.00         1\n",
      "          Joint Venture       0.00      0.00      0.00         1\n",
      " Joint Venture _ Filing       0.75      1.00      0.86         3\n",
      "     License_Agreements       0.56      1.00      0.71         5\n",
      "            Maintenance       0.19      0.83      0.31         6\n",
      "          Manufacturing       0.00      0.00      0.00         1\n",
      "              Marketing       0.00      0.00      0.00         3\n",
      "Non_Compete_Non_Solicit       0.00      0.00      0.00         1\n",
      "            Outsourcing       0.00      0.00      0.00         9\n",
      "              Promotion       0.00      0.00      0.00         2\n",
      "               Reseller       0.00      0.00      0.00         1\n",
      "                Service       0.60      0.38      0.46         8\n",
      "            Sponsorship       0.44      0.80      0.57         5\n",
      "     Strategic Alliance       0.28      0.71      0.40         7\n",
      "                 Supply       0.50      0.33      0.40         3\n",
      "         Transportation       0.00      0.00      0.00         4\n",
      "\n",
      "               accuracy                           0.41       102\n",
      "              macro avg       0.32      0.34      0.30       102\n",
      "           weighted avg       0.39      0.41      0.36       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# testing the model and classification report \n",
    "y_pred = lr_model.predict(avg_wv_test_features)\n",
    "print(classification_report(test_label_names_set, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkS9N6_7ObD2"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jL_POJwrOL4j",
    "outputId": "07f1132b-a768-4d99-d971-b55b8a99d7a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, random_state=42)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the dataframe to the SVM algorithm \n",
    "#training the model with the training data\n",
    "svm_model = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm_model.fit(avg_wv_train_features, train_label_names_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "N2XRvvPpOhxo"
   },
   "outputs": [],
   "source": [
    "#testing the model \n",
    "y_pred = svm_model.predict(avg_wv_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um95M052OkbS",
    "outputId": "0a78a079-09c6-4f38-98f5-b4783bce0f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "   Affiliate_Agreements       0.00      0.00      0.00         0\n",
      "      Agency Agreements       0.20      0.50      0.29         2\n",
      "            Co_Branding       0.50      0.75      0.60         4\n",
      "          Collaboration       0.57      0.57      0.57         7\n",
      "  Consulting Agreements       1.00      0.67      0.80         3\n",
      "            Development       0.40      0.40      0.40         5\n",
      "            Distributor       0.88      0.64      0.74        11\n",
      "            Endorsement       0.00      0.00      0.00         1\n",
      "  Endorsement Agreement       0.00      0.00      0.00         1\n",
      "              Franchise       1.00      1.00      1.00         3\n",
      "                Hosting       0.50      0.20      0.29         5\n",
      "                     IP       0.50      1.00      0.67         1\n",
      "          Joint Venture       0.00      0.00      0.00         1\n",
      " Joint Venture _ Filing       0.60      1.00      0.75         3\n",
      "     License_Agreements       0.67      0.80      0.73         5\n",
      "            Maintenance       0.29      0.83      0.43         6\n",
      "          Manufacturing       0.25      1.00      0.40         1\n",
      "              Marketing       0.00      0.00      0.00         3\n",
      "Non_Compete_Non_Solicit       0.00      0.00      0.00         1\n",
      "            Outsourcing       0.00      0.00      0.00         9\n",
      "              Promotion       1.00      0.50      0.67         2\n",
      "               Reseller       0.00      0.00      0.00         1\n",
      "                Service       0.80      0.50      0.62         8\n",
      "            Sponsorship       0.50      0.80      0.62         5\n",
      "     Strategic Alliance       0.38      0.43      0.40         7\n",
      "                 Supply       0.67      0.67      0.67         3\n",
      "         Transportation       1.00      0.50      0.67         4\n",
      "\n",
      "               accuracy                           0.52       102\n",
      "              macro avg       0.43      0.47      0.42       102\n",
      "           weighted avg       0.53      0.52      0.49       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#classification model\n",
    "print(classification_report(test_label_names_set, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "5XDtWsPYOnRX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LegalTextAnalysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
